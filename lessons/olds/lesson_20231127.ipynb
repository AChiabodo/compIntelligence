{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Search and Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need to study games?\n",
    "Usually games are *easy to formalize* and can be *good models* for real-world problems with competitive (or cooperative) activities.  \n",
    "Games are also a good testbench for AI methods.  \n",
    "The main goal is to find an **optimal policy** for the agent which can be seen as a \"black box\" that takes the current state as input and returns the action to be taken.  \n",
    "Another possible goal is to find the **optimal ply** for each state.  \n",
    "*Ply* : how to move in response to a move by the opponent.   \n",
    "We can have different types of games:  \n",
    "- **Deterministic games**: the next state is completely determined by the current state and the action taken by the agent. The agent can always know the next state. For example Chess.\n",
    "- **Probabilistic games**: the next state is determined by the current state, the action taken by the agent and a random event. The agent cannot always know the next state. For example Backgammon or Poker.\n",
    "- **Real Time** : the agent has a limited amount of time to decide the action to take. For example FPS games.\n",
    "- **Turn based** : the agent has unlimited time to decide the action to take. For example Chess.\n",
    "- **Perfect information** : the agent knows the complete state of the game. For example Chess.\n",
    "- **Imperfect information** : the agent does not know the complete state of the game. For example Poker.\n",
    "- **Zero-sum** : the gain of one player is the loss of the other player. For example Chess.\n",
    "- **Non-zero-sum** : the gain of one player is not the loss of the other player. For example Soccer.  \n",
    "Chess is a deterministic, turn based, perfect information, zero-sum game.\n",
    "Poker is a probabilistic, turn based, imperfect information, zero-sum game.\n",
    "Nuclear war is a probabilistic, real time, imperfect information, non-zero-sum game. (also marriage)\n",
    "\n",
    "There are many difference between games and search problems:\n",
    "- We don't know how the opponent will play. The goal / solution in a game is to find the perfect strategy (policy) to win the game. In a search problem we know the goal and we want to find the optimal path to reach it.\n",
    "- Efficiency is important in games. We need to find the best move in a limited amount of time. But also, branching factor is usually higher in games than in search problems (pruning is much more important in games than in search, for example avoiding all moves that I know being useless).\n",
    "\n",
    "#### Deterministic games\n",
    "We have a certain number of players, a set of states (how we represent a certain situation), a set of possible actions, a transition model, a terminal test and a utility function. \n",
    "For terminal states we use the terminal test/function to do a static evaluation of the state to know if we've win or not.\n",
    "We can define a **game tree** as a tree where each node is a state and each edge is an action. The root is the initial state and the leaves are the terminal states.  \n",
    "We can imagine that the root is the current state after my move and the first layer are the possible moves that my opponent can made. The second layer are the possible moves that I can made after the opponent move and so on.\n",
    "An example can be with tic-tac-toe. The root is the empty board, the first layer are the possible moves that the first player can made, the second layer are the possible moves that the second player can made after the first player move and so on.  \n",
    "In the tic-tac-toe example our strategy that wants to maximize the win probability would be to start with one of the corner cells. In this case starting second after a \"perfect\" strategy we would be unable to win, but only to draw by blocking every move of our opponent.\n",
    "\n",
    "#### Minimax algorithm\n",
    "One of the most famous algorithm for games is the minimax algorithm. It's used to **minimize the maximum loss** in a loosing scenario.  \n",
    "Remember that maximizing our chances of winning and minimizing the loss are **NOT** the same thing.  \n",
    "In a so-called MinMax game, the two players are called **Max** and **Min**.  \n",
    "In each state, Max will choose the action that maximizes the utility function and Min will choose the action that minimizes the utility function. \n",
    "A possible implementation is based on a recursive approach with a sign-flip at each level, in this way we're always \"maximizing\" our function.  \n",
    "It's a complete strategy only if the tree is finite, is optimal only against an optimal opponent and is optimal only if the opponent is playing to win. The complexity is $ O(b^m) $ in time and $ O(b*m) $ in space where b is the branching factor and m is the maximum depth of the tree.  \n",
    "\n",
    "We can rewrite the classic tic-tac-toe game as a \"Pick 3 numbers whose sum is 12\" game. In this way is easier to see the game tree and to find if a state is winning or not. This is also a good example of how is possible to transform a problem into an easier one simply by changing the representation of the problem. \n",
    "```python\n",
    "def won(cells):\n",
    "    return any([sum(cells[i] for i in combo) == 12 for combo in combos])\n",
    "def minmax(board):\n",
    "    ...\n",
    "```\n",
    "To handle games with *more than two players*, we can also using the minmax algorithm just with more layers (and a change in the sign-flip).  \n",
    "The state space of a game usually is HUGE, for example chess has $ 10^{120} $ possible states. In this case the MinMax algorithm is not feasible.   \n",
    "#### Alpha-Beta pruning\n",
    "To avoid to explore the entire tree we can use a technique called **Alpha-Beta pruning**. \"If you have an idea that is surely bad, don't waste time to see how bad it is\". In this way we can avoid to explore some branches of the tree that cointain only \"bad\" (or useless) states.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chess and AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First automaton built in 1912 by Leonardo Torres y Quevedo. Only able to win with a king and a rook vs a King. Not optimal nor complete.\n",
    "Alan Turing then develope the Turochamp in 1948. Based on very basic rules and a lot of pruning. It was able to solve mate in 2 problems.\n",
    "In 1950 Claude Shannon wrote a paper about how to program a computer to play chess. Given the size of all the possible states of the game ( about $ 10^120 $) , he suggested to use static evaluation of the current state of the game.\n",
    "\n",
    "deep blue vs kasparov : 1997, first time that a computer won against a world champion. Based on the work of Shannon, pruning, and a bit of machine learning (other than a LOT of hardware).  \n",
    "\n",
    "A main characteristic of chess engine is the **hard cut off**. It's a limit on the depth of the tree that the engine can explore. It's used to avoid to spend too much time on a single move and making the problem feasible in a certain amount of time.\n",
    "*Horizon Effect*: when the engine incorrectly estimates the value of a move beacause it's just beyond it's hard cut off.  \n",
    "*Quiescence search* : increase dept of the search when a move is *volatile* (when its value changes a lot from level to level).We need to be able to discriminate between \"quiet\" and \"queiscent\" positions.  \n",
    "Possible techniques to improve the performance of a chess engine:\n",
    "-  **Hash Table** : store the value of a static position that has been already evaluated. In this way we can avoid to re-evaluate the same position multiple times.\n",
    "-  **Lookup tables** : Store the value of all known opening moves and endgames. In this way we can avoid to evaluate them and already know what to use. For endgame we'll nee to find a canonical representation of the board to store them.  \n",
    "\n",
    "Machine Learning can be used to \"learn\" the value of certain position to be able to evaluate them without the need of a static evaluation function.\n",
    "\n",
    "#### Stochastic games\n",
    "How can we incorporate randomness in our game tree? We can modify the minmax algorithm to take into account the probability of each action and then try to maximize the *expected* reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a Policy search is a \"black box\" that contains a set of rules to follow to play the game.  \n",
    "The outcome is NOT deterministic, because it vary depending on the opponent. Example of policy search are the min-max algorithm and the LCS algorithm.  \n",
    "A downside of min-max is that the opponent is assumed to be optimal, and minimizing the worst possible outcome is not always the best strategy, for example in investing that should be to not invest at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Classifier Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not related with today classifiers. They're based on trigger-action rules. They're a machine learning system with close links to reinforced learning and *genetic algorithm*.\n",
    "We can see LCS as a framework that uses genetic algorithms to study learning conditions in rule-based systems. As of today they're completely outdated and useless. \n",
    "Create a certain number of rules where we have a tuple (condition,action) and we can \"learn\" those.\n",
    "Costituited of:\n",
    "- Input Interface : creating some kind of input starting from the real world, and providing a \"valid\" description about that\n",
    "- message list : big databases of \"facts\"\n",
    "- Classifier List : set of **rules** that are used to take decisions, composed of IF condition AND condition (...) THEN action. The conditions are usually a subset of the message list. The action is usually a subset of the possible actions. For example \"IF squillero_talking AND is_thursday THEN squillero_is_teaching\". That's not about probabilities, but about facts and rules.\n",
    "- Output Interaface : If there is some facts in the message queues, then do something in the real world.  \n",
    "For example \"IF there_is_fire THEN call_firefighters\".In this case we can have an input interface that read temperature, a Classifier List that contains \"IF temperature > 100 THEN there_is_fire\" and an output interface that calls firefighters.  \n",
    "\n",
    "The main problems in LCS are about how to create the rules and how to update them. Holland propose to have a GA that can update the existing rules. Now the problem is to define a **fitness** function to evaluate a rule. Note that the rule-set represent the current knowledge of the system.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

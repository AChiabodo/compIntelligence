{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Search and Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The study of games is essential because they are often **simple to formalize** and serve as **effective models** for real-world scenarios involving competitive or cooperative dynamics. Additionally, games provide an excellent platform for testing artificial intelligence (AI) methodologies.\n",
    "\n",
    "The primary objective in adversarial search is to develop an **optimal policy** for an agent. This policy can be visualized as a \"black box\" that receives the current state as input and outputs the subsequent action to execute. Another aim is to determine the **optimal ply**—the best move in response to the opponent's action—for each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Study Games in AI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Games are **intuitive models** for real-world problems featuring competitive or cooperative elements and serve as a robust testing ground for AI techniques.\n",
    "\n",
    "**Key Objectives:**\n",
    "- **Optimal Policy**: A strategy that dictates the best action for an agent based on the current state.\n",
    "- **Optimal Ply**: The ideal countermove in reaction to an opponent's move.\n",
    "\n",
    "**Game Types:**\n",
    "- **Deterministic**: The next state is fully determined by the current state and the agent's action. Example: Chess.\n",
    "- **Probabilistic**: The next state depends on the current state, the agent's action, and a random event. Example: Backgammon, Poker.\n",
    "- **Real-Time**: The agent must decide actions within a limited timeframe. Example: First-Person Shooter (FPS) games.\n",
    "- **Turn-Based**: The agent has no time constraints to decide actions. Example: Chess.\n",
    "- **Perfect Information**: The agent has full knowledge of the game's state. Example: Chess.\n",
    "- **Imperfect Information**: The agent lacks complete knowledge of the game's state. Example: Poker.\n",
    "- **Zero-Sum**: One player's gain is another player's loss. Example: Chess.\n",
    "- **Non-Zero-Sum**: A player's gain does not necessarily result in another player's loss. Example: Soccer.\n",
    "\n",
    "**Examples:**\n",
    "- Chess is a deterministic, turn-based, perfect information, zero-sum game.\n",
    "- Poker is a probabilistic, turn-based, imperfect information, zero-sum game.\n",
    "- Nuclear war is a probabilistic, real-time, imperfect information, non-zero-sum game. The same can be humorously said for marriage.\n",
    "\n",
    "**Differences Between Games and Search Problems:**\n",
    "\n",
    "Games and search problems, while similar in their use of algorithms and strategies, exhibit key differences:\n",
    "\n",
    "1. **Predictability of Opponent's Play**: In games, the opponent's strategy is unknown, making the goal to devise a perfect strategy (policy) to win. In contrast, search problems have a defined goal, and the task is to find the optimal path to that goal.\n",
    "\n",
    "2. **Importance of Efficiency**: Time is a critical factor in games; finding the best move quickly is essential. Moreover, games typically have a higher branching factor than search problems, making pruning strategies crucial to eliminate futile moves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterministic Games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic games involve a defined number of players, a set of states representing various situations, a collection of possible actions, a transition model, a terminal test, and a utility function. The terminal test or function is used for a static evaluation of terminal states to determine a win or loss.\n",
    "\n",
    "A **game tree** is a theoretical model used in game theory and artificial intelligence to represent possible moves in a game. Each node symbolizes a unique state of the game, while each edge denotes a potential action that transitions from one state to another. The root node corresponds to the initial state of the game, often right after a move has been made, and the leaf nodes represent the terminal states where the game concludes.\n",
    "\n",
    "**Key Properties of a Game Tree:**\n",
    "- **Branching Factor**: This refers to the average number of child nodes for each node in the tree, indicating the average number of possible actions from any given state.\n",
    "- **Depth**: The depth of the tree reflects the number of layers, which correlates to the number of moves that have been played in the game.\n",
    "- **Symmetries**: Symmetries in a game tree reveal the presence of identical nodes, which can occur due to the repetitive nature of certain games.\n",
    "\n",
    "Consider the game of tic-tac-toe:\n",
    "- The root node is the empty board.\n",
    "- The first layer consists of all possible moves by the first player.\n",
    "- The second layer contains all possible responses by the second player, and so on.\n",
    "\n",
    "In tic-tac-toe, a strategy aimed at maximizing the probability of winning might involve starting with one of the corner squares. If we play second against a \"perfect\" strategy, our best outcome is a draw by countering every move of the opponent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimax Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The **minimax algorithm** is a well-known strategy for turn-based games where two players, often referred to as **Max** and **Min**, compete against each other.  \n",
    "Max aims to maximize the utility function, while Min seeks to minimize it.  \n",
    "The algorithm's purpose is to **minimize the maximum possible loss** in scenarios where losing is inevitable.\n",
    "\n",
    "It's crucial to understand that maximizing the chances of winning is not equivalent to minimizing potential losses.\n",
    "\n",
    "**Key Aspects:**\n",
    "- The algorithm typically employs a recursive approach with alternating signs at each level, effectively maximizing the utility function from the perspective of the current player.\n",
    "- It is a complete and optimal strategy only if the game tree is finite and both players are playing optimally with the intent to win.\n",
    "- The computational complexity is \\( O(b^m) \\) in time and \\( O(b \\cdot m) \\) in space, where \\( b \\) is the branching factor and \\( m \\) is the maximum depth of the tree.\n",
    "\n",
    "**Adapting to Different Scenarios:**\n",
    "- The minimax algorithm can be adapted for games with more than two players by adding additional layers and modifying the sign-flipping mechanism.\n",
    "- For games with vast state spaces, such as chess with approximately \\( 10^{120} \\) possible states, the minimax algorithm becomes impractical due to its complexity.\n",
    "\n",
    "**Transforming Problems:**\n",
    "- Games like tic-tac-toe can be reformulated into different representations, such as the \"Pick 3 numbers whose sum is 12\" game, to simplify the visualization of the game tree and determine winning states.\n",
    "\n",
    "```python\n",
    "def won(cells):\n",
    "    return any(sum(cells[i] for i in combo) == 12 for combo in combos)\n",
    "\n",
    "def minimax(board):\n",
    "    val = eval_terminal(*board) # 0 if not terminal, 1 if won, -1 if lost\n",
    "    possible = list(set(range(9)) - board[0] - board[1])\n",
    "    if val != 0 or not possible:\n",
    "        return None, val\n",
    "    evaluatiations = []\n",
    "    for ply in possible:\n",
    "        new_board = (board[1], board[0] | {move})\n",
    "        _, val = minimax(new_board)\n",
    "        evaluations.append((move, val))\n",
    "    return max(evaluations, key=lambda x: x[1])\n",
    "```\n",
    "\n",
    "The major limitation of the minimax algorithm is that it is **computationally infeasible** for games with large state spaces. For example, the game of chess has a branching factor of approximately 31 and a maximum depth of 100, resulting in a state space of \\( 31^{100} \\). This is far too large to compute in a reasonable amount of time.\n",
    "\n",
    "**Limitations of the Minimax Algorithm**\n",
    "\n",
    "The **minimax algorithm** faces significant challenges when applied to games with extensive state spaces due to its computational demands. For instance, the game of chess, which is often used to benchmark AI algorithms, has an estimated state-space complexity of \\( 10^{46} \\) and a game tree complexity of \\( 10^{123} \\), based on an average branching factor of 35 and an average game length of 80 ply⁶. These figures highlight the impracticality of using the minimax algorithm for exhaustive search in such complex games.\n",
    "\n",
    "To address these limitations, various enhancements and alternatives to the minimax algorithm have been developed, such as **alpha-beta pruning**, which reduces the number of nodes evaluated by the algorithm, and **iterative deepening**, which allows the algorithm to use a more manageable depth of search¹."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha-Beta Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid to explore the entire tree we can use a technique called **Alpha-Beta pruning**.  \n",
    "\"If you have an idea that is surely bad, don't waste time to see how bad it is\". Following this approach we can avoid to explore some branches of the tree that cointain only \"bad\" (or useless) states and compute the same exact minmax with only a fraction of the complexity.\n",
    "\n",
    "**How It Works:**\n",
    "- Two values, **alpha** and **beta**, are used to keep track of the minimum score that the maximizing player is assured of (alpha) and the maximum score that the minimizing player is assured of (beta).\n",
    "- As the algorithm traverses the game tree, branches that cannot possibly influence the final decision are \"pruned\" or cut off, meaning they are not explored further.\n",
    "- This pruning occurs when the minimax value of one node is less than the alpha value or greater than the beta value, indicating that the parent node will not select this child node.\n",
    "\n",
    "**Benefits:**\n",
    "- **Efficiency**: Alpha-beta pruning can dramatically decrease the number of nodes that need to be examined, making it more feasible to search deeper in the game tree.\n",
    "- **Optimality**: Despite pruning parts of the tree, alpha-beta pruning still guarantees the same result as the standard minimax algorithm, assuming perfect play.\n",
    "\n",
    "**Example:**\n",
    "Consider a simple game tree where the maximizing player (Max) starts the game and the minimizing player (Min) follows:\n",
    "- If Max has an alpha value of 5 and encounters a node with a value less than 5, Max can ignore this node and its descendants.\n",
    "- Conversely, if Min has a beta value of 3 and finds a node with a value greater than 3, Min can disregard this node and its descendants.\n",
    "\n",
    "By applying alpha-beta pruning, the algorithm avoids unnecessary calculations, leading to faster and more efficient gameplay decisions without sacrificing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chess and AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Evolution of Chess and AI**\n",
    "\n",
    "The journey of artificial intelligence in chess began with the first automaton created by Leonardo Torres y Quevedo in 1912. This rudimentary machine was capable of winning a chess endgame with a king and rook against a lone king, although it was neither optimal nor complete in its strategy.\n",
    "\n",
    "In 1948, Alan Turing developed the Turochamp, a chess program based on basic rules and extensive pruning techniques. Despite its simplicity, it could solve mate-in-two problems, demonstrating early potential for AI in chess.\n",
    "\n",
    "Claude Shannon's seminal paper in 1950 laid the groundwork for programming computers to play chess. Faced with the immense number of possible game states, estimated at \\( 10^{120} \\), Shannon proposed using static evaluation to assess the current state of the game.\n",
    "\n",
    "The historic match between IBM's Deep Blue and world champion Garry Kasparov in 1997 marked the first time a computer defeated a reigning world champion. Deep Blue's victory was built upon Shannon's principles, advanced pruning techniques, and a touch of machine learning, supported by substantial hardware capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts in Chess Engines:**\n",
    "- **Hard Cut-Off**: A limitation on the depth of the search tree that a chess engine can explore, ensuring that the engine makes timely decisions without excessive computation.\n",
    "- **Horizon Effect**: A phenomenon where the engine misjudges the value of a move because it falls just beyond the hard cut-off.\n",
    "- **Quiescence Search**: An extension of the search depth for volatile moves, whose value fluctuates significantly from one level to the next, requiring differentiation between \"quiet\" and \"quiescent\" positions.\n",
    "\n",
    "**Enhancing Chess Engine Performance:**\n",
    "- **Hash Tables**: By storing the evaluated values of static positions, hash tables prevent redundant evaluations, improving efficiency.\n",
    "- **Lookup Tables**: Pre-storing the values of known opening moves and endgames allows engines to bypass evaluation, relying instead on established knowledge. For endgames, a canonical board representation is necessary for effective storage.\n",
    "\n",
    "**The Role of Machine Learning:**\n",
    "Machine learning has revolutionized chess engines by enabling them to learn the value of positions, thereby bypassing the need for static evaluation functions. This adaptive approach allows engines to improve over time, learning from vast datasets and past games to enhance their strategic depth and decision-making prowess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Games and the Minimax Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of stochastic games, randomness plays a crucial role in determining the outcome of each move. To adapt the traditional minimax algorithm for such games, we introduce probabilities for each action, aiming to maximize the **expected reward** rather than a certain outcome.\n",
    "\n",
    "The modified algorithm, often referred to as the **expectiminimax algorithm**, calculates the **minimum expected reward** for the maximizing player by considering the probabilities of reaching different states from a given state after an action. The formula for this expected reward is as follows:\n",
    "$$\n",
    "Value(s) = \\max_{a \\in A(s)} \\min_{s' \\in S} \\sum_{s' \\in S} P(s'|s,a) \\cdot Utility(s')\n",
    "$$\n",
    "where:\n",
    "- $Value(s)$ is the expected utility of state $ s $,\n",
    "- $ A(s) $ is the set of available actions in state $ s $,\n",
    "- $ S $ is the set of possible successor states,\n",
    "- $ P(s'|s,a) $ is the probability of reaching state $s'$ from state $s$ after action $a$,\n",
    "- $ Utility(s') $ is the reward of state $ s' $.\n",
    "\n",
    "Alpha-beta pruning can still be applied to reduce the computational complexity of the expectiminimax algorithm. By pruning branches that will not affect the final decision, we can avoid evaluating a vast number of game tree nodes, thus making the algorithm more efficient.\n",
    "\n",
    "It's important to note that while alpha-beta pruning is effective in deterministic games, its application in stochastic games requires careful consideration of the probabilities associated with each move. The pruning decisions must take into account the expected utilities rather than the absolute values of the game tree nodes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Strategies\n",
    "### (1+1)-ES , (1+\\lambda)-ES , (1,\\lambda)-ES\n",
    "Changes the pool that I'm using to find the best solution\n",
    "- (1+1)-ES is a first-imporvement algorithm that only keeps the best solution where tweak\n",
    "- (1+\\lambda)-ES is a first-improvement algorithm that keeps the best \\lambda solutions where tweak\n",
    "- (1,\\lambda)-ES is a steepest-step algorithm where \\lambda is the sample size and tweak() is performed using a gaussian mutation like (1,1)\n",
    "    The current solution is *always* replaced by the best solution found in the sample, even if it's worse. Using a bigger sample size \\lambda, the algorithm is more likely to find a better solution (or just \"similar\" to the current, lowering the risk of loosing the current state), but it's also more expensive.\n",
    "Causality vs weak causality:\n",
    " - Causality: The evaluation function is \"smooth\" and our sampling will return \"coherent\" results, driving us to the best solution\n",
    " - Weak causality: The evaluation function is more \"randomic\" and our sampling can return very different result even with little change\n",
    "(1,\\lambda) generates all the \\lambda solutions from the starting\n",
    "The normal distribution is a good choice for the mutation, but how do we select the step-size \\sigma? We can use random guess, experience or meta-optimize it.\n",
    "### Dynamic Strategies\n",
    "We have the correct balance between exploration and exploitation when the number of successful mutations is *around 1/5* of the total mutations. We can use this to dynamically change the balance between exploration and exploitation, by tweaking the step-size \\sigma (diminuishing it to increase exploitation). Is also required some time to see the results of the change, so we need to keep \\sigma fixed for some iterations (called *era*).\n",
    "*Endogenous Parameter* : is a parameter that the algorithm is able to set the by itself without the user intervention \n",
    "*Problem Space* : parameters that the user is required to set into the parameter\n",
    "Our goal is to find the best value for \\sigma, we can adopt *self-adaptation* to exploit \\sigma as a endogenous parameter by putting \\sigma into the list of problem parameters and let the algorithm find the best value for it.\n",
    "First thing we'll need to mutate \\sigma and the parameters in *different* steps, calling learning rate \\tau the step-size for \\sigma given by 1/sqrt{n} where n is the number of parameters. We can use the following formula to mutate \\sigma:\n",
    "\\sigma' = \\sigma * e^{\\tau * N(0,1)}\n",
    "where N(0,1) is a random number from a normal distribution with mean 0 and variance 1.\n",
    "\\v' = N(v_i, \\sigma')\n",
    "Here we are computing the new sigma and then using it to compute the new values\n",
    "Remember to always mutate sigma *before* the parameters, otherwise the parameters will be mutated with the old sigma.\n",
    "### Self-Adaptation with double learning rate\n",
    "Another strategy is to have two different learning rates, one \"global\" learning rate and another \"coordinate-wise\" (axis-specific) learning rate. The global learning rate is used to mutate the sigma, while the coordinate-wise learning rate is used to mutate the parameters. We can have multidimensional parameters with axis that have different \"importance\" and/or variance.\n",
    "### Covariance Matrix Adaptation Evolution Strategy (CMA-ES)\n",
    "We also add k parameters to the problem (\\alpha_1 ... \\alpha_k) that are used to compute the Covariance Matrix C given by\n",
    "c_ii = \\sigma_i^2.\n",
    "c_ij = \\sigma_i * \\sigma_j * \\rho_{ij}\n",
    "where \\rho_{ij} is the correlation between the parameters i and j.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Computation\n",
    "Evolutionary algorithm are those capable of evolving a population of solutions to a problem, using the principles of natural selection. The population is initialized with random solutions, then the algorithm iterates over the population, selecting the best solutions and using them to generate new solutions. The new solutions are then evaluated and the best ones are selected again. The process is repeated until a stop condition is met.\n",
    "\n",
    "The basic idea of evolution is the *accumulation* of tiny variations over time. These variations can be obtained though *mutation* and *selection*.\n",
    "    - variations : mostly random changes in the solution, random process\n",
    "    - selection : the best solutions are selected to generate new solutions, deterministic process\n",
    "In evolutions all the changes are not designed but only evaluated, it's not a random process but a *blind* process that gets \"material\" from the randomness.\n",
    "Evolution is not an optimization process, it does not have a goal, nor strenght, nor intelligence\n",
    "In Practice Evolutionary Algorithm are based on population-based metaheuristics\n",
    "Candidate solution -> inidividual\n",
    "set of Candidate solutions -> Population\n",
    "Ability to solve our problem -> Fitness\n",
    "Sequence of steps -> Generation\n",
    "- Individual : Encode a *potential solution* for the problem, for example a list of numbers, a string, a tree, a graph, a set of rules, a neural network, etc.\n",
    "- Parent Selection - we select some individual and use them as \"parents\" for the future generation, their \"genome\" is passed down to new individuals that are re-inserted into the population\n",
    "- Evaluation and selection - We evaluate our current population based on some euristics "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

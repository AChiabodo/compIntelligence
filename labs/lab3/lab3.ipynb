{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB3\n",
    "\n",
    "Wrote a local-search algorithm (eg. an EA) able to solve the *Problem* instances 1, 2, 5, and 10 on a 1000-loci genomes, using a minimum number of fitness calls. That's all.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: Sunday, November 26 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "* Reviews: Sunday, December 3 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, November 27\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import lab3_lib\n",
    "from lab3_lib import AbstractProblem\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "\n",
    "    class Crossover(Enum):\n",
    "        RANDOM = 1\n",
    "        MULTI_CUT = 2\n",
    "        SCRAMBLE = 3\n",
    "        CYCLE = 4\n",
    "\n",
    "    class AgentType(Enum):\n",
    "        BINARY = 1\n",
    "        PATTERN = 2\n",
    "\n",
    "    def __init__(self,genome,mutation_rate : float = None) -> None:\n",
    "        self.genome = genome\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self._id = random.randint(0, 1000000000)\n",
    "        pass\n",
    "\n",
    "    def set_mutation_rate(self, mutation_rate : float) -> None:\n",
    "        self.mutation_rate = mutation_rate\n",
    "\n",
    "    def set_genome(self, genome) -> None:\n",
    "        self.genome = genome\n",
    "\n",
    "    def compute_fitness(self) -> None:\n",
    "        pass        \n",
    "\n",
    "    def load_agent(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            self.genome = pickle.load(f)\n",
    "        return self\n",
    "    \n",
    "    def save_agent(self, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self.genome, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentGA(Agent):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(None,None)\n",
    "\n",
    "    def set_genome(self,genome_size : int,genome : list = None) -> Agent:\n",
    "        if genome is None:\n",
    "            genome = [random.uniform(0, 1) < 0.5 for _ in range(genome_size)]\n",
    "        super().set_genome(genome)\n",
    "        return self\n",
    "\n",
    "    def set_mutation_rate(self,mutation_rate : float) -> Agent:\n",
    "        super().set_mutation_rate(mutation_rate)\n",
    "        return self\n",
    "\n",
    "    def mutation(self,mutation_rate : float = None) -> Agent:\n",
    "        if mutation_rate is None and self.mutation_rate is None:\n",
    "            raise ValueError(\"Mutation rate not set\")\n",
    "        mask = [random.uniform(0, 1) < (mutation_rate if mutation_rate is not None else self.mutation_rate) for _ in range(len(self.genome))]\n",
    "        self.genome = [a ^ b for a, b in zip(self.genome, mask)]\n",
    "        if self.mutation_rate is not None:\n",
    "            self.mutation_rate *= [0.999,1.001][random.randint(0,1)]\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"AgentGA({self._id},{self.fitness})\"\n",
    "\n",
    "    def crossover(self,other : Agent,crossover_type : Agent.Crossover = Agent.Crossover.RANDOM,other_weight = 0.5) -> Agent:\n",
    "        match crossover_type:\n",
    "            case Agent.Crossover.RANDOM:\n",
    "                return self.random_crossover(other,other_weight)\n",
    "            case Agent.Crossover.MULTI_CUT:\n",
    "                return self.multi_cut_crossover(other)\n",
    "            case Agent.Crossover.SCRAMBLE:\n",
    "                return self.scramble_crossover(other)\n",
    "            case Agent.Crossover.CYCLE:\n",
    "                return self.cycle_crossover(other)\n",
    "            case _:\n",
    "                raise ValueError(\"Unknown crossover type\")\n",
    "\n",
    "    def random_crossover(self,other : Agent,other_weight = 0.5) -> Agent:\n",
    "        #print(\"crossover\")\n",
    "        for (i,_) in enumerate(self.genome):\n",
    "            self.genome[i] = random.choices([self.genome[i],other.genome[i]],weights=[1-other_weight,other_weight])[0]\n",
    "        return self\n",
    "    \n",
    "    def multi_cut_crossover(self,other : Agent) -> Agent:\n",
    "        #print(\"multi_cut_crossover\")\n",
    "        n = random.randint(1, len(self.genome)//2-1)\n",
    "        size = len(self.genome)//n\n",
    "        for i in range(n):\n",
    "            start = i * size\n",
    "            end = (i + 1) * size - 1\n",
    "            n = random.randint(start, end)\n",
    "            m = random.randint(start, end)\n",
    "            if n > m:\n",
    "                n,m = m,n\n",
    "            self.genome[n:m] = other.genome[n:m]\n",
    "        return self\n",
    "\n",
    "    def scramble_crossover(self,other : Agent) -> Agent: #TODO rewrite and rename as One Point Crossover\n",
    "        #print(\"scramble_mutation\")\n",
    "        n = random.randint(0, len(self.genome)-1)\n",
    "        self.genome[n:] = other.genome[n:]\n",
    "        return self\n",
    "    \n",
    "    def cycle_crossover(self,other : Agent) -> Agent:\n",
    "        #print(\"cycle_crossover\")\n",
    "        n = random.randint(0, len(self.genome)-1)\n",
    "        m = random.randint(0, len(self.genome)-1)\n",
    "        if n > m:\n",
    "            n,m = m,n\n",
    "        self.genome[n:m] = other.genome[n:m]\n",
    "        return self\n",
    "\n",
    "    def compute_fitness(self,fitness_function : AbstractProblem) -> None:\n",
    "        #print(f\"compute_fitness : {fitness_function.calls}\")\n",
    "        self._fitness = fitness_function(self.genome)\n",
    "    \n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentTraining():\n",
    "\n",
    "    class trainingType(Enum):\n",
    "        DEFAULT = 0\n",
    "        LAMBDA = 1\n",
    "        TOURNAMENT = 2\n",
    "\n",
    "    def __init__(self, pop_size : int,problem  : AbstractProblem,training_type : trainingType = 0,k : int = 50,fast_finish : bool = False) -> None:\n",
    "        self.population = []\n",
    "        self.state = problem\n",
    "        self.ration = 0.9\n",
    "        self.temperature = 0.9\n",
    "        self.lam = 10\n",
    "        self.fast_finish = fast_finish\n",
    "        \n",
    "        for _ in range(pop_size):\n",
    "            temp = AgentGA(choices([0, 1], k = k),self.state)\n",
    "            self.population.append(temp)\n",
    "        match training_type:\n",
    "            case self.trainingType.DEFAULT:\n",
    "                self.generation = self.generation_default\n",
    "            case self.trainingType.LAMBDA:\n",
    "                self.generation = self.generation_lambda\n",
    "            case self.trainingType.TOURNAMENT:\n",
    "                self.generation = self.generation_tournament\n",
    "\n",
    "    def generation_default(self) -> None:\n",
    "        for _ in range(len(self.population)):\n",
    "            parent_1 , parent_2 = deepcopy(random.choices(self.population,weights=[x.fitness for x in self.population],k=2))\n",
    "            if random.random() > self.ration :\n",
    "                parent_1.crossover(parent_2,AgentGA.Crossover.RANDOM)\n",
    "            else:\n",
    "                parent_1.mutation(self.ration/2)\n",
    "            parent_1.compute_fitness(self.state)\n",
    "            self.population.append(parent_1)    \n",
    "        self.population.sort(key=lambda x : x.fitness , reverse=True)\n",
    "        self.population = self.population[:len(self.population)//2]\n",
    "       \n",
    "\n",
    "    def generation_lambda(self) -> None:\n",
    "        parents = []\n",
    "        # (mu,lambda) approach with lambda = mu for semplicity\n",
    "        for _ in range(self.lam): # Selecting parents randomly\n",
    "            #parents.append(self.population.pop(random.randint(0,len(self.population)-1)) )\n",
    "            parents.append(self.population.pop(0) )\n",
    "        for parent in parents:\n",
    "            temp_population = []\n",
    "            temp_population.append(deepcopy(parent))\n",
    "            for _ in range(self.lam):\n",
    "                temp : Agent = deepcopy(parent).mutation(self.ration)\n",
    "                temp.compute_fitness(self.state)\n",
    "                temp_population.append(temp)  \n",
    "            temp_population.sort(key=lambda x : x.fitness , reverse=True)\n",
    "            self.population.append(temp_population[0])  \n",
    "        self.population.sort(key=lambda x : x.fitness , reverse=True)\n",
    "        \n",
    "    def train(self,epoch = 10):\n",
    "        fitness = []\n",
    "        avg_fitness = []\n",
    "        print(\"Starting Training\")\n",
    "        for _ in range(epoch):\n",
    "            print(\"Generation : \",_)\n",
    "            self.generation()\n",
    "            print(f\"Best fitness : {self.population[0].fitness} , individual : {self.population[0].genome}\")\n",
    "            fitness.append(self.population[0].fitness)\n",
    "            avg_fitness.append(sum([x.fitness for x in self.population])/len(self.population))\n",
    "            if self.fast_finish and self.population[0].fitness == 1.0:\n",
    "                break\n",
    "            self.ration = self.temperature * self.ration\n",
    "        return self.population[0] , fitness , avg_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternBasedAgent(Agent):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        #self.pattern_size = random.randint(1,genome_size//10)\n",
    "        super().__init__(None,None)\n",
    "        \n",
    "    def set_genome(self,genome_size : int,genome : list = None) -> Agent:\n",
    "        self.genome_size = genome_size\n",
    "        self.pattern_size = random.randint(max(1,genome_size//50),genome_size//10)\n",
    "        self.pattern = [random.uniform(0, 1) < 0.5 for _ in range(self.pattern_size)]\n",
    "        self.generate_genome()\n",
    "        return self\n",
    "    \n",
    "    def set_mutation_rate(self,mutation_rate : float) -> Agent:\n",
    "        super().set_mutation_rate(mutation_rate)\n",
    "        return self\n",
    "\n",
    "    def generate_genome(self):\n",
    "        self.genome = list(chain.from_iterable([self.pattern for _ in range(self.genome_size//self.pattern_size + 1)])) # overshoot the size to be sure to have enough\n",
    "        self.genome = self.genome[:self.genome_size]\n",
    "        #print(f\"size : {self.pattern_size} with pattern : {self.pattern} , genome : {self.genome}\")\n",
    "\n",
    "    def mutation(self,mutation_rate : float = None) -> Agent:\n",
    "        if mutation_rate is None and self.mutation_rate is None:\n",
    "            raise ValueError(\"Mutation rate not set\")\n",
    "        \n",
    "        if random.random() < 0.1 :\n",
    "            adding = random.choices([-1, 1], weights=[1, 2])[0]\n",
    "            if adding == -1 and self.pattern_size > 1:\n",
    "                self.pattern_size -= 1\n",
    "                self.pattern = self.pattern[:-1]\n",
    "            else:\n",
    "                temp = random.choices([0, 1], k = adding)\n",
    "                self.pattern_size += adding\n",
    "                self.pattern += temp\n",
    "        else:\n",
    "            for (i,state) in enumerate(self.pattern):\n",
    "                if random.random() < (mutation_rate if mutation_rate is not None else self.mutation_rate) :\n",
    "                    self.pattern[i] = 1-state\n",
    "        self.generate_genome()\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"AgentGA({self._id},{self.fitness}) with pattern {self.pattern}\"\n",
    "\n",
    "    def crossover(self,other : Agent,crossover_type : Agent.Crossover = 1,other_weight = 0.5) -> Agent:\n",
    "        match crossover_type:\n",
    "            case Agent.Crossover.RANDOM:\n",
    "                return self.random_crossover(other,other_weight)\n",
    "            case Agent.Crossover.MULTI_CUT:\n",
    "                return self.multi_cut_crossover(other)\n",
    "            case Agent.Crossover.SCRAMBLE:\n",
    "                return self.one_cut_crossover(other)\n",
    "            case Agent.Crossover.CYCLE:\n",
    "                return self.cycle_crossover(other)\n",
    "            case _:\n",
    "                raise ValueError(\"Unknown crossover type\")\n",
    "\n",
    "    def random_crossover(self,other : Agent,other_weight = 0.5) -> Agent:\n",
    "        #print(\"crossover\")\n",
    "        offset = self.pattern_size - other.pattern_size\n",
    "        if offset > 0:\n",
    "            temp = random.randint(0,offset)\n",
    "            for (i,_) in enumerate(other.pattern):\n",
    "                self.pattern[i + temp] = random.choices([self.pattern[i + temp],other.pattern[i]],weights=[1-other_weight,other_weight])[0]\n",
    "        else:\n",
    "            temp = random.randint(0,abs(offset))\n",
    "            for (i,_) in enumerate(self.pattern):\n",
    "                self.pattern[i] = random.choices([self.genome[i],other.genome[i + temp]],weights=[1-other_weight,other_weight])[0]\n",
    "        self.generate_genome()\n",
    "        return self\n",
    "    \n",
    "    def multi_cut_crossover(self,other : Agent) -> Agent:\n",
    "        #print(\"multi_cut_crossover\")\n",
    "        for _ in range(random.randint(0, (min(self.pattern_size , other.pattern_size) - 1)//2)):\n",
    "            n = random.randint(0, min(self.pattern_size , other.pattern_size) - 1)\n",
    "            m = random.randint(0, min(self.pattern_size , other.pattern_size) - 1)\n",
    "            if n > m:\n",
    "                n,m = m,n\n",
    "            self.pattern[n:m] = other.pattern[n:m]\n",
    "        self.generate_genome()\n",
    "        return self\n",
    "\n",
    "    def one_cut_crossover(self,other : Agent) -> Agent:\n",
    "        #print(\"scramble_mutation\")\n",
    "        n = random.randint(0, min(self.pattern_size , other.pattern_size) - 1)\n",
    "        self.pattern[n:] = other.pattern[n:]\n",
    "        self.generate_genome()\n",
    "        return self\n",
    "    \n",
    "    def cycle_crossover(self,other : Agent) -> Agent:\n",
    "        #print(\"cycle_crossover\")\n",
    "        RuntimeError(\"Not yet implemented\")\n",
    "        n = random.randint(0, len(self.genome)-1)\n",
    "        m = random.randint(0, len(self.genome)-1)\n",
    "        if n > m:\n",
    "            n,m = m,n\n",
    "        self.genome[n:m] = other.genome[n:m]\n",
    "        return self\n",
    "\n",
    "    def compute_fitness(self,fitness_function : AbstractProblem) -> None:\n",
    "        #print(f\"compute_fitness : {fitness_function.calls}\")\n",
    "        self._fitness = fitness_function(self.genome)\n",
    "    \n",
    "    @property\n",
    "    def fitness(self):\n",
    "        return self._fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(agent_list):\n",
    "    # Calcola la probabilità di ciascun agente rispetto al totale\n",
    "    total_agents = len(agent_list)\n",
    "    probabilities = [agent.fitness / total_agents for agent in agent_list]\n",
    "\n",
    "    # Calcola l'entropia utilizzando la formula di Shannon\n",
    "    entropy = -sum(p * math.log2(p) if p > 0 else 0 for p in probabilities)\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rule(agent_list : list):\n",
    "    # Calcola la media delle regole di tutti gli agenti\n",
    "    total_agents = len(agent_list)\n",
    "    total_rules = len(agent_list[0].genome)\n",
    "    average = [0 for _ in range(total_rules)]\n",
    "\n",
    "    for agent in agent_list:\n",
    "        for i in range(total_rules):\n",
    "            average[i] += agent.genome[i]\n",
    "\n",
    "    average = [x / total_agents for x in average]\n",
    "\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "class AgentIslandsTraining():\n",
    "\n",
    "    def __init__(self, pop_size : int,problem  : AbstractProblem,k : int = 50,island_number : int = 10,agent_type : Agent.AgentType = Agent.AgentType.BINARY) -> None:\n",
    "        self.state = problem\n",
    "        self.starting_mutation_rate = 0.008\n",
    "        self.ration = 0.8\n",
    "        self.mutation_rate = self.starting_mutation_rate\n",
    "        self.old_fitness = None\n",
    "        self.static_epochs = 0\n",
    "        self.islands = [ [] for _ in range(island_number)]\n",
    "        print(\"Creating Islands\")\n",
    "        print(f\"Islands : {self.islands}\")\n",
    "\n",
    "        match agent_type:\n",
    "            case Agent.AgentType.BINARY:\n",
    "                CurrentAgent = AgentGA\n",
    "            case Agent.AgentType.PATTERN:\n",
    "                CurrentAgent = PatternBasedAgent\n",
    "\n",
    "        for island in self.islands:\n",
    "            for _ in range(pop_size // island_number):\n",
    "                temp : Agent = CurrentAgent().set_genome(genome_size=k).set_mutation_rate(random.uniform(0.001, 0.006))\n",
    "                temp.compute_fitness(self.state)\n",
    "                island.append(temp)\n",
    "            print(f\"Islands : {[len(x) for x in self.islands]}\")\n",
    "\n",
    "    def process_island(self,args):\n",
    "        i, island, size, ration, state = args\n",
    "        for _ in range(size):\n",
    "            parent, other = random.choices(island, k=2)\n",
    "            parent = deepcopy(parent)\n",
    "            if random.random() > ration:\n",
    "                parent.crossover(other, Agent.Crossover.MULTI_CUT)\n",
    "            parent.mutation()\n",
    "            parent.compute_fitness(state)\n",
    "            island.append(parent)\n",
    "        island.sort(key=lambda x: x.fitness, reverse=True)\n",
    "        return island[:size]\n",
    "\n",
    "    def parallel_generation(self):\n",
    "        args_list = [(i, island, len(island), self.ration, self.state) for i, island in enumerate(self.islands)]\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            new_islands = list(executor.map(self.process_island, args_list))\n",
    "\n",
    "        self.islands = new_islands\n",
    "\n",
    "    def generation(self) -> None:\n",
    "        for i , island in enumerate(self.islands):      \n",
    "            #print(f\"Island : {i} with {len(island)} pop\")\n",
    "            size = len(island)\n",
    "            for _ in range(size):\n",
    "                #parent , other = random.choices(island,weights=[x.fitness for x in island],k=2)\n",
    "                parent , other = random.choices(island,k=2)\n",
    "                #print(f\"parent : {parent} , other : {other}\")\n",
    "                parent = deepcopy(parent)\n",
    "                if random.random() > self.ration :\n",
    "                    parent.crossover(other,Agent.Crossover.MULTI_CUT)\n",
    "                #parent.mutation(self.mutation_rate / 2)\n",
    "                parent.mutation()\n",
    "                parent.compute_fitness(self.state)\n",
    "                island.append(parent)    \n",
    "            island.sort(key=lambda x : x.fitness , reverse=True)\n",
    "            self.islands[i] = island[:size]\n",
    "            #print(f\"Islands : {[len(x) for x in self.islands]} at iteration {i}\")\n",
    "            #print(f\"Island : {i} with {len(island)} pop\")\n",
    "    \n",
    "    def generation_tournament(self) -> None:\n",
    "        for i , island in enumerate(self.islands):      \n",
    "            current_member = 0\n",
    "            mating_pool = []\n",
    "            while current_member < self.lam:\n",
    "                tournament = random.choices(island,k=self.tournament_size)\n",
    "                tournament.sort(key=lambda x : x.fitness , reverse=True)\n",
    "                mating_pool.append(tournament[0])\n",
    "                current_member += 1\n",
    "            temp_population = []\n",
    "            for parent in mating_pool:\n",
    "                for _ in range(self.lam):\n",
    "                    temp : Agent = deepcopy(parent).mutation(self.ration)\n",
    "                    temp.compute_fitness(self.state)\n",
    "                    temp_population.append(temp)  \n",
    "            temp_population.sort(key=lambda x : x.fitness , reverse=True)\n",
    "            self.islands[i][-self.lam:] = temp_population[:self.lam]\n",
    "\n",
    "        #define what to do if num_islands is odd\n",
    "    def migration(self , N : int = 1):\n",
    "        if len(self.islands) == 1:\n",
    "            return\n",
    "        for i in range(len(self.islands)-1) :\n",
    "            for _ in range(N):\n",
    "                pos_1 = random.randint(0,len(self.islands[i]) - 1)\n",
    "                pos_2 = random.randint(0,len(self.islands[(i+1)%len(self.islands)]) - 1)\n",
    "                self.islands[i][pos_1] , self.islands[(i+1)%len(self.islands)][pos_2] =  self.islands[(i+1)%len(self.islands)][pos_2] , self.islands[i][pos_1]\n",
    "               \n",
    "\n",
    "    def train(self,generations = 10):\n",
    "        best_fitness = None\n",
    "        print(\"Starting Training\")\n",
    "        for gen in range(generations):\n",
    "            #print(f\"Islands : {[len(x) for x in self.islands]} at gen {gen}\")\n",
    "            self.generation()\n",
    "            #print(f\"Islands : {[len(x) for x in self.islands]} at gen {gen}\")\n",
    "            if (gen + 1 ) % 10 == 0:\n",
    "                best_fitness = max([agent for island in self.islands for agent in island], key=lambda agent: agent.fitness)\n",
    "                self.migration(30)\n",
    "                if self.old_fitness == best_fitness:\n",
    "                    self.static_epochs += 1\n",
    "                else:\n",
    "                    self.static_epochs = 0\n",
    "                    self.old_fitness = best_fitness\n",
    "                if self.static_epochs > 2:\n",
    "                    self.mutation_rate = min(self.starting_mutation_rate,1.05 * self.mutation_rate)\n",
    "                    #self.ration = max(0.6,1.1 * self.ration)\n",
    "                else:\n",
    "                    self.mutation_rate = max(self.starting_mutation_rate/10,0.95 * self.mutation_rate)\n",
    "                    self.ration = max(0.4,0.99 * self.ration)\n",
    "                print(f\"Best fitness : {best_fitness.fitness} at gen {gen+1} with criterion : {self.ration} , mutation : {best_fitness.mutation_rate} , static_epochs : {self.static_epochs}\")\n",
    "                temp = average_rule([agent for island in self.islands for agent in island])\n",
    "                print(f\"Average sum : {sum(temp) / 1000} , rule weight : {temp}\")\n",
    "                #print(f\"Best fitness : {best_fitness.fitness} at gen {gen} with total population : {([calculate_entropy(x) for x in self.islands])} , criterion : {self.ration}\")\n",
    "            #self.islands.sort(key=lambda x : x[0].fitness , reverse=True)\n",
    "            if best_fitness is not None and best_fitness.fitness == 1.0:\n",
    "                break\n",
    "        print([island for island in self.islands])\n",
    "        return best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Islands\n",
      "Islands : [[], [], [], [], []]\n",
      "Islands : [20, 0, 0, 0, 0]\n",
      "Islands : [20, 20, 0, 0, 0]\n",
      "Islands : [20, 20, 20, 0, 0]\n",
      "Islands : [20, 20, 20, 20, 0]\n",
      "Islands : [20, 20, 20, 20, 20]\n",
      "Starting Training\n",
      "Best fitness : 0.4718 at gen 10 with criterion : 0.792 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.5259900000000001 , rule weight : [0.3, 0.6, 0.29, 0.72, 0.44, 0.61, 0.61, 0.7, 0.72, 0.51, 0.49, 0.36, 0.66, 0.45, 0.49, 0.29, 0.42, 0.79, 0.3, 0.13, 0.99, 0.62, 0.8, 0.8, 0.2, 0.5, 0.29, 0.16, 0.7, 0.4, 0.72, 0.58, 0.52, 0.3, 0.5, 0.55, 0.42, 0.6, 0.6, 0.28, 0.52, 0.56, 0.58, 0.41, 0.62, 0.74, 0.6, 0.62, 0.78, 0.61, 0.3, 0.47, 0.62, 0.57, 0.47, 0.42, 0.33, 0.39, 0.72, 0.64, 0.63, 0.38, 0.71, 0.56, 0.66, 0.71, 0.57, 0.8, 0.31, 0.22, 0.8, 0.62, 0.38, 0.8, 0.28, 0.34, 0.4, 0.33, 0.41, 0.4, 0.52, 0.18, 0.8, 0.37, 0.82, 0.67, 0.7, 0.7, 0.6, 0.4, 0.08, 0.42, 0.76, 0.5, 0.22, 0.8, 0.24, 0.22, 0.8, 0.37, 0.6, 0.6, 0.62, 0.8, 0.69, 0.75, 0.6, 0.48, 0.32, 0.53, 0.82, 0.49, 0.52, 0.41, 0.23, 0.37, 0.49, 0.89, 0.42, 0.49, 0.48, 0.4, 0.48, 0.85, 0.71, 0.48, 0.42, 0.3, 0.73, 0.49, 0.72, 0.47, 0.7, 0.28, 0.32, 0.58, 0.4, 0.7, 0.8, 0.2, 0.59, 0.52, 0.8, 0.58, 0.6, 0.52, 0.58, 0.39, 0.42, 0.22, 0.71, 0.48, 0.52, 0.58, 0.33, 0.64, 0.37, 0.62, 0.21, 0.31, 0.72, 0.4, 0.31, 0.8, 0.49, 0.48, 0.75, 0.99, 0.57, 0.8, 0.57, 0.17, 0.6, 0.51, 0.52, 0.38, 0.6, 0.1, 0.52, 0.27, 0.61, 0.6, 0.9, 0.38, 0.9, 0.72, 0.66, 0.5, 0.72, 0.61, 0.32, 0.52, 0.2, 0.42, 0.34, 0.67, 0.22, 0.6, 0.64, 0.01, 0.6, 0.4, 0.6, 0.77, 0.52, 0.87, 0.61, 0.55, 0.62, 0.63, 0.39, 0.6, 0.92, 0.41, 0.3, 0.38, 0.14, 0.75, 0.49, 0.44, 0.82, 0.49, 0.4, 0.48, 0.62, 0.5, 0.68, 0.45, 0.52, 0.1, 0.73, 0.49, 0.62, 0.6, 0.48, 0.62, 0.4, 0.82, 0.43, 0.42, 0.3, 0.3, 0.4, 0.37, 0.62, 0.74, 0.72, 0.48, 0.72, 0.52, 0.32, 0.37, 0.7, 0.6, 0.41, 0.58, 0.52, 0.69, 0.43, 0.64, 0.71, 0.51, 1.0, 0.9, 0.39, 0.52, 0.55, 0.43, 0.37, 0.29, 0.88, 0.6, 0.31, 0.38, 0.3, 0.37, 0.6, 0.58, 0.7, 0.1, 0.49, 0.33, 0.31, 0.7, 0.72, 0.62, 0.52, 0.62, 0.78, 0.43, 0.4, 0.37, 0.8, 0.1, 0.2, 0.5, 0.46, 0.3, 0.72, 0.45, 0.66, 0.4, 0.8, 0.61, 0.8, 0.8, 0.48, 0.8, 0.49, 0.76, 0.82, 0.61, 0.31, 0.6, 0.3, 0.18, 0.4, 0.67, 0.38, 0.24, 0.69, 0.47, 0.32, 0.84, 0.6, 0.38, 0.72, 0.58, 0.9, 0.52, 0.48, 0.22, 0.75, 0.33, 0.53, 0.79, 0.2, 0.62, 0.4, 0.45, 0.42, 0.58, 0.82, 0.38, 0.32, 0.59, 0.68, 0.43, 0.52, 0.2, 0.52, 0.42, 0.3, 0.62, 0.48, 0.8, 0.5, 0.9, 0.5, 0.51, 0.43, 0.44, 0.31, 0.76, 0.7, 0.6, 0.53, 0.58, 0.6, 0.46, 0.55, 0.54, 0.69, 0.5, 0.48, 0.18, 0.22, 0.6, 0.7, 0.43, 0.92, 0.52, 0.8, 0.45, 0.5, 0.82, 0.56, 0.27, 0.7, 0.12, 0.8, 0.4, 0.72, 0.28, 0.22, 0.37, 0.3, 0.6, 0.76, 0.38, 0.31, 0.6, 0.22, 0.6, 0.7, 0.8, 0.72, 0.9, 0.5, 0.72, 0.66, 0.4, 0.74, 0.31, 0.31, 0.28, 0.42, 0.29, 0.5, 0.34, 0.78, 0.43, 0.79, 0.79, 0.61, 0.61, 0.38, 0.32, 0.62, 0.52, 0.92, 0.62, 0.3, 0.31, 0.33, 0.46, 0.52, 0.88, 0.32, 0.39, 0.2, 0.3, 0.52, 0.65, 0.72, 0.68, 0.6, 0.3, 0.9, 0.65, 0.28, 0.4, 0.6, 0.56, 0.3, 0.72, 0.4, 0.7, 0.58, 0.57, 0.82, 0.67, 0.85, 0.72, 0.41, 0.48, 0.68, 0.57, 0.31, 0.21, 0.71, 0.54, 0.47, 0.51, 0.19, 0.51, 0.39, 0.42, 0.42, 0.32, 0.58, 0.42, 0.58, 0.27, 0.8, 0.53, 0.33, 0.88, 0.92, 0.3, 0.5, 0.27, 0.9, 0.18, 0.42, 0.58, 0.4, 0.3, 0.59, 0.5, 0.58, 0.8, 0.42, 0.82, 0.61, 0.6, 0.58, 0.57, 0.5, 0.6, 0.92, 0.58, 0.79, 0.63, 0.34, 0.26, 0.41, 0.7, 0.4, 0.11, 0.52, 0.31, 0.16, 0.85, 0.51, 0.71, 0.72, 0.79, 0.5, 0.5, 0.49, 0.45, 0.82, 0.3, 0.6, 0.3, 0.35, 0.39, 0.72, 0.35, 0.49, 0.5, 0.7, 0.58, 0.4, 0.9, 0.56, 0.12, 0.5, 0.34, 0.62, 0.66, 0.38, 0.52, 0.2, 0.59, 0.3, 0.8, 0.6, 0.59, 0.8, 0.4, 0.8, 0.75, 0.57, 0.5, 0.43, 0.51, 0.62, 0.61, 0.39, 0.32, 0.61, 0.38, 0.55, 0.41, 0.37, 0.52, 0.87, 0.26, 0.62, 0.68, 0.72, 0.4, 0.9, 0.5, 0.58, 0.48, 0.43, 0.3, 0.8, 0.48, 0.7, 0.4, 0.3, 0.49, 0.52, 0.52, 0.5, 0.3, 0.1, 0.42, 0.44, 0.85, 0.33, 0.87, 0.64, 0.68, 0.52, 0.68, 0.7, 0.27, 0.8, 0.5, 0.41, 0.35, 0.34, 0.61, 0.31, 0.42, 0.72, 0.51, 0.52, 0.89, 0.46, 0.75, 0.57, 0.36, 0.61, 0.31, 0.52, 0.48, 0.62, 0.38, 0.69, 0.57, 0.4, 0.58, 0.53, 0.29, 0.5, 0.52, 0.38, 0.72, 0.41, 0.9, 0.5, 0.62, 0.7, 0.51, 0.28, 0.27, 0.8, 0.44, 0.4, 0.4, 0.5, 0.52, 0.52, 0.55, 0.91, 0.6, 0.82, 0.6, 0.8, 0.51, 0.43, 0.64, 0.31, 0.25, 0.99, 0.62, 0.19, 0.32, 0.09, 0.21, 0.37, 0.39, 0.69, 0.3, 0.79, 0.18, 0.42, 0.75, 0.9, 0.68, 0.8, 0.58, 0.72, 0.53, 0.21, 0.42, 1.0, 0.31, 0.43, 0.42, 0.48, 0.4, 0.6, 0.44, 0.5, 0.38, 0.42, 0.78, 0.66, 0.8, 0.58, 0.67, 0.36, 0.41, 0.72, 0.58, 0.62, 0.62, 0.4, 0.6, 0.51, 0.85, 0.24, 0.21, 0.31, 0.52, 0.38, 0.68, 0.32, 0.56, 0.58, 0.43, 0.89, 0.59, 0.6, 0.54, 0.7, 0.18, 0.6, 0.59, 0.4, 0.72, 0.5, 0.21, 0.53, 0.43, 0.82, 0.6, 0.38, 0.92, 0.26, 0.45, 0.6, 0.22, 0.7, 0.48, 0.32, 0.38, 0.52, 0.53, 0.42, 0.6, 0.51, 0.54, 0.42, 0.52, 0.58, 0.72, 0.69, 0.52, 0.8, 0.81, 0.45, 0.62, 0.41, 0.28, 0.7, 0.6, 0.4, 0.08, 0.41, 0.14, 0.85, 0.44, 0.99, 0.58, 0.91, 0.38, 0.53, 0.92, 0.66, 0.8, 0.62, 0.14, 0.59, 0.53, 0.21, 0.5, 0.38, 0.45, 0.52, 0.48, 0.6, 0.1, 0.49, 0.2, 0.32, 0.57, 0.42, 0.78, 0.58, 0.6, 0.32, 0.9, 0.44, 0.3, 0.82, 0.8, 0.32, 0.42, 0.48, 0.62, 0.59, 0.5, 0.74, 0.49, 0.51, 0.71, 0.7, 0.39, 0.48, 0.44, 0.56, 0.27, 0.89, 0.59, 0.72, 0.39, 0.38, 0.52, 0.42, 0.9, 0.8, 0.41, 0.18, 0.4, 0.41, 0.28, 0.8, 0.78, 0.42, 0.68, 0.62, 0.5, 0.32, 0.47, 0.7, 0.3, 0.12, 0.29, 0.6, 0.48, 0.58, 0.42, 0.9, 0.66, 0.62, 0.9, 0.5, 0.61, 0.56, 0.57, 0.5, 0.29, 0.77, 0.4, 0.31, 0.39, 0.51, 0.55, 0.23, 0.48, 0.51, 0.06, 0.65, 0.49, 0.49, 0.72, 0.89, 0.8, 0.52, 1.0, 0.69, 0.8, 0.2, 0.25, 0.8, 0.13, 0.4, 0.5, 0.52, 0.1, 0.72, 0.25, 0.62, 0.4, 0.62, 0.88, 0.41, 0.7, 0.38, 0.6, 0.38, 0.74, 0.7, 0.72, 0.44, 0.5, 0.2, 0.55, 0.5, 0.8, 0.6, 0.29, 0.78, 0.43, 0.42, 0.48, 0.51, 0.5, 0.62, 0.39, 0.7, 0.41, 0.45, 0.45, 0.99, 0.31, 0.7, 0.59, 0.08, 0.42, 0.78, 0.55, 0.72, 0.58, 0.62, 0.3, 0.35, 0.41, 0.78, 0.37, 0.52, 0.32, 0.6, 0.6, 0.3, 0.63, 0.48, 0.32, 0.32, 0.7, 0.42, 0.57, 0.58, 0.22, 0.68, 0.79, 0.43, 0.68, 0.8, 0.88, 0.7, 0.57, 0.62, 0.44, 0.47, 0.42, 0.31, 0.29, 0.52, 0.52, 0.49, 0.3, 0.71, 0.56, 0.95, 0.79, 0.69, 0.99, 0.65, 0.27, 0.4, 0.32, 0.52, 0.6, 0.62, 0.18, 0.12, 0.49, 0.23, 0.58, 0.62, 0.18]\n",
      "Best fitness : 0.55 at gen 20 with criterion : 0.78408 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.548150000000001 , rule weight : [0.8, 0.8, 0.8, 0.74, 0.64, 0.2, 0.23, 0.99, 1.0, 0.11, 0.0, 0.22, 0.23, 0.6, 0.8, 0.8, 0.8, 0.8, 0.2, 0.27, 1.0, 1.0, 1.0, 1.0, 0.24, 0.2, 0.23, 0.2, 0.8, 0.8, 0.2, 0.8, 0.0, 0.8, 0.0, 0.59, 0.8, 0.2, 0.0, 0.0, 0.66, 0.2, 0.8, 0.2, 1.0, 0.8, 0.2, 1.0, 1.0, 0.8, 0.6, 0.8, 1.0, 0.8, 0.54, 0.44, 0.0, 0.03, 0.99, 0.8, 0.31, 0.2, 0.42, 0.23, 0.8, 1.0, 1.0, 0.8, 0.8, 0.0, 0.47, 1.0, 0.8, 0.8, 0.8, 0.04, 0.0, 0.23, 0.2, 0.8, 0.8, 0.0, 0.6, 0.2, 1.0, 0.2, 0.79, 1.0, 0.2, 0.0, 0.0, 0.66, 0.4, 0.8, 0.0, 0.8, 0.6, 0.0, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 1.0, 0.74, 0.64, 0.0, 0.03, 0.79, 1.0, 0.31, 0.0, 0.22, 0.03, 0.6, 0.8, 1.0, 0.8, 0.8, 0.0, 0.27, 0.8, 1.0, 1.0, 1.0, 0.24, 0.2, 0.23, 0.2, 0.8, 0.8, 0.2, 0.6, 0.0, 0.8, 0.0, 0.59, 1.0, 0.0, 0.2, 0.2, 0.86, 0.4, 1.0, 0.2, 1.0, 0.6, 0.0, 0.8, 1.0, 1.0, 0.6, 0.8, 0.8, 0.8, 0.54, 0.64, 0.0, 0.03, 0.79, 0.8, 0.11, 0.2, 0.42, 0.23, 0.8, 1.0, 1.0, 0.8, 0.8, 0.0, 0.47, 0.8, 0.8, 0.8, 0.8, 0.04, 0.2, 0.03, 0.4, 1.0, 1.0, 0.2, 0.8, 0.2, 1.0, 0.0, 0.59, 0.8, 0.2, 0.2, 0.0, 0.66, 0.2, 0.8, 0.0, 1.0, 0.6, 0.0, 0.8, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 0.74, 0.64, 0.0, 0.03, 0.79, 1.0, 0.11, 0.0, 0.22, 0.03, 0.6, 1.0, 0.8, 1.0, 1.0, 0.2, 0.47, 1.0, 1.0, 1.0, 0.8, 0.04, 0.0, 0.23, 0.4, 0.8, 0.8, 0.0, 0.6, 0.0, 1.0, 0.0, 0.59, 0.8, 0.0, 0.0, 0.2, 0.86, 0.4, 1.0, 0.2, 1.0, 0.6, 0.0, 0.8, 1.0, 0.8, 0.6, 0.8, 0.8, 0.8, 0.74, 0.44, 0.2, 0.23, 0.99, 1.0, 0.31, 0.2, 0.42, 0.03, 0.6, 0.8, 1.0, 1.0, 0.8, 0.0, 0.27, 0.8, 0.8, 1.0, 0.8, 0.04, 0.0, 0.03, 0.2, 1.0, 1.0, 0.2, 0.8, 0.2, 1.0, 0.0, 0.59, 0.8, 0.2, 0.0, 0.0, 0.66, 0.2, 0.8, 0.2, 0.8, 0.8, 0.2, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8, 0.8, 0.54, 0.64, 0.2, 0.03, 0.79, 0.8, 0.11, 0.0, 0.42, 0.03, 0.6, 0.8, 0.8, 0.8, 1.0, 0.2, 0.47, 1.0, 1.0, 1.0, 0.8, 0.04, 0.0, 0.23, 0.2, 0.8, 0.8, 0.0, 0.6, 0.2, 0.8, 0.2, 0.79, 1.0, 0.2, 0.2, 0.2, 0.86, 0.2, 0.8, 0.0, 1.0, 0.8, 0.0, 0.8, 0.8, 0.8, 0.6, 1.0, 0.8, 0.8, 0.54, 0.44, 0.0, 0.23, 0.99, 1.0, 0.31, 0.2, 0.42, 0.03, 0.6, 0.8, 1.0, 0.8, 0.8, 0.0, 0.27, 0.8, 1.0, 0.8, 1.0, 0.24, 0.2, 0.23, 0.4, 1.0, 1.0, 0.0, 0.6, 0.0, 1.0, 0.2, 0.59, 0.8, 0.0, 0.0, 0.0, 0.86, 0.2, 0.8, 0.0, 0.8, 0.6, 0.2, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8, 0.8, 0.54, 0.64, 0.0, 0.03, 0.79, 0.8, 0.11, 0.2, 0.22, 0.23, 0.8, 1.0, 1.0, 1.0, 1.0, 0.2, 0.27, 0.8, 0.8, 1.0, 1.0, 0.04, 0.0, 0.03, 0.2, 0.8, 1.0, 0.0, 0.6, 0.0, 0.8, 0.0, 0.79, 1.0, 0.2, 0.2, 0.2, 0.86, 0.2, 0.8, 0.0, 1.0, 0.6, 0.0, 0.8, 0.8, 0.8, 0.8, 0.8, 1.0, 1.0, 0.74, 0.64, 0.2, 0.23, 0.99, 0.8, 0.11, 0.0, 0.42, 0.23, 0.6, 0.8, 0.8, 0.8, 0.8, 0.2, 0.27, 0.8, 0.8, 0.8, 0.8, 0.24, 0.2, 0.23, 0.4, 1.0, 1.0, 0.0, 0.6, 0.0, 1.0, 0.0, 0.59, 0.8, 0.0, 0.0, 0.2, 0.66, 0.4, 1.0, 0.2, 1.0, 0.8, 0.2, 1.0, 0.8, 0.8, 0.6, 1.0, 1.0, 0.8, 0.54, 0.44, 0.0, 0.03, 0.99, 0.8, 0.11, 0.0, 0.22, 0.03, 0.8, 1.0, 1.0, 1.0, 1.0, 0.2, 0.27, 0.8, 0.8, 1.0, 0.8, 0.04, 0.0, 0.03, 0.2, 1.0, 0.8, 0.2, 0.8, 0.2, 1.0, 0.2, 0.79, 1.0, 0.0, 0.0, 0.0, 0.86, 0.4, 0.8, 0.0, 0.8, 0.6, 0.0, 1.0, 0.8, 0.8, 0.6, 0.8, 0.8, 1.0, 0.74, 0.64, 0.2, 0.23, 0.99, 0.8, 0.11, 0.0, 0.42, 0.03, 0.6, 0.8, 0.8, 0.8, 1.0, 0.0, 0.47, 1.0, 1.0, 1.0, 1.0, 0.24, 0.2, 0.03, 0.2, 0.8, 1.0, 0.2, 0.6, 0.0, 0.8, 0.0, 0.59, 1.0, 0.0, 0.0, 0.0, 0.66, 0.2, 1.0, 0.2, 1.0, 0.8, 0.2, 1.0, 0.8, 0.8, 0.6, 1.0, 0.8, 0.8, 0.54, 0.44, 0.0, 0.23, 0.79, 1.0, 0.31, 0.2, 0.42, 0.23, 0.8, 1.0, 0.8, 0.8, 0.8, 0.2, 0.47, 0.8, 0.8, 0.8, 0.8, 0.04, 0.2, 0.03, 0.2, 0.8, 0.8, 0.0, 0.8, 0.2, 1.0, 0.2, 0.79, 1.0, 0.0, 0.0, 0.0, 0.86, 0.2, 0.8, 0.0, 0.8, 0.6, 0.2, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.74, 0.44, 0.0, 0.03, 0.99, 1.0, 0.11, 0.0, 0.22, 0.03, 0.6, 1.0, 0.8, 0.8, 0.8, 0.0, 0.27, 1.0, 1.0, 1.0, 1.0, 0.24, 0.2, 0.03, 0.2, 0.8, 1.0, 0.0, 0.6, 0.0, 0.8, 0.0, 0.79, 0.8, 0.2, 0.2, 0.2, 0.86, 0.4, 1.0, 0.2, 0.8, 0.6, 0.0, 1.0, 1.0, 0.8, 0.6, 0.8, 0.8, 0.8, 0.74, 0.44, 0.0, 0.03, 0.79, 0.8, 0.31, 0.2, 0.42, 0.23, 0.8, 1.0, 0.8, 0.8, 0.8, 0.2, 0.27, 0.8, 0.8, 0.8, 0.8, 0.24, 0.0, 0.23, 0.4, 1.0, 1.0, 0.2, 0.8, 0.2, 0.8, 0.0, 0.59, 1.0, 0.2, 0.0, 0.0, 0.66, 0.2, 0.8, 0.2, 0.8, 0.6, 0.0, 0.8, 0.8, 1.0, 0.8, 1.0, 1.0, 1.0, 0.74, 0.44, 0.0, 0.03, 0.99, 0.8, 0.11, 0.0, 0.22, 0.03, 0.8, 0.8, 1.0, 1.0, 1.0, 0.2, 0.47, 1.0, 1.0, 0.8, 0.8, 0.04, 0.2, 0.23, 0.2, 0.8, 0.8, 0.0, 0.6, 0.2, 0.8, 0.0, 0.59, 0.8, 0.0, 0.2, 0.2, 0.86, 0.4, 1.0, 0.2, 0.8, 0.6, 0.0, 1.0, 0.8, 0.8, 0.6, 0.8, 0.8, 1.0, 0.54, 0.64, 0.2, 0.23, 0.99, 1.0, 0.31, 0.2, 0.22, 0.03, 0.6, 1.0, 1.0, 0.8, 0.8, 0.0, 0.27, 0.8, 1.0, 0.8, 0.8, 0.04, 0.0, 0.03, 0.4, 1.0, 1.0, 0.2, 0.8, 0.2, 0.8, 0.0, 0.59, 1.0, 0.0, 0.0, 0.0, 0.66, 0.2, 1.0, 0.0, 1.0, 0.8, 0.2, 1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.74, 0.64, 0.0, 0.03, 0.79, 0.8, 0.11, 0.2, 0.22, 0.03, 0.6, 0.8, 0.8, 1.0, 1.0, 0.2, 0.47, 1.0, 1.0, 0.8, 0.8, 0.04, 0.2, 0.03, 0.2, 0.8, 0.8, 0.0, 0.8, 0.0, 1.0, 0.2, 0.79, 1.0, 0.2, 0.2, 0.2, 0.66, 0.2, 0.8, 0.2, 1.0, 0.6, 0.0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.54, 0.44, 0.2, 0.23, 0.99, 1.0, 0.31, 0.2, 0.22, 0.03, 0.6, 1.0, 0.8, 0.8, 0.8, 0.0, 0.27, 1.0, 0.8, 1.0, 1.0, 0.24, 0.2, 0.23, 0.4, 1.0, 0.8, 0.0, 0.6, 0.2, 1.0, 0.0, 0.59, 0.8, 0.0, 0.0, 0.2, 0.66, 0.2, 0.8, 0.0, 0.8, 0.8, 0.2, 1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.74, 0.44, 0.0, 0.03, 0.79, 0.8, 0.31, 0.0, 0.42, 0.23, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.27, 0.8, 1.0, 1.0, 0.8, 0.04, 0.0, 0.03, 0.2, 1.0, 0.8, 0.0]\n",
      "Best fitness : 0.63 at gen 30 with criterion : 0.7762392 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.5875299999999998 , rule weight : [1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.44, 1.0, 0.0, 0.0, 0.0, 0.87, 0.0, 1.0, 0.0, 1.0, 0.63, 0.0, 1.0, 1.0, 1.0, 0.13, 1.0, 0.95, 1.0, 0.73, 0.37, 0.0, 0.08, 1.0, 1.0, 0.46, 0.21, 0.63, 0.31, 0.71, 1.0, 0.98, 1.0, 1.0, 0.02, 0.53, 1.0, 1.0, 0.99, 1.0, 0.1, 0.5, 0.16, 0.02, 1.0, 1.0, 0.06]\n",
      "Best fitness : 0.67 at gen 40 with criterion : 0.768476808 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.6420000000000005 , rule weight : [1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03, 1.0, 0.0, 1.0, 0.0, 0.21, 1.0, 0.0, 0.0, 0.0, 0.79, 0.0, 1.0, 0.0, 1.0, 0.79, 0.0, 1.0, 1.0, 1.0, 0.21, 1.0, 1.0, 1.0, 0.99, 0.37, 0.18, 0.21, 1.0, 1.0, 0.99, 0.2, 0.6, 0.61, 1.0, 1.0, 1.0, 0.98, 1.0, 0.11, 0.92, 1.0, 1.0, 1.0, 1.0, 0.03, 0.84, 0.34, 0.2, 1.0, 1.0, 0.03]\n",
      "Best fitness : 0.73 at gen 50 with criterion : 0.76079203992 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.6829999999999996 , rule weight : [1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.39, 0.28, 0.21, 1.0, 1.0, 1.0, 0.35, 0.89, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.81, 0.36, 0.66, 1.0, 1.0, 0.22]\n",
      "Best fitness : 0.75 at gen 60 with criterion : 0.7531841195208 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.7168000000000007 , rule weight : [1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.59, 0.48, 0.22, 1.0, 1.0, 1.0, 0.63, 0.75, 0.89, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.76, 0.84, 0.4, 0.94, 1.0, 1.0, 0.24]\n",
      "Best fitness : 0.77 at gen 70 with criterion : 0.745652278325592 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.7483999999999991 , rule weight : [1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.92, 0.9, 0.38, 1.0, 1.0, 1.0, 0.28, 0.99, 0.99, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.49, 1.0, 1.0, 1.0, 0.06]\n",
      "Best fitness : 0.8 at gen 80 with criterion : 0.7381957555423361 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.7698999999999995 , rule weight : [1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.93, 1.0, 0.52, 1.0, 1.0, 1.0, 0.36, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.93, 1.0, 0.52, 1.0, 1.0, 0.97, 0.39, 0.97, 0.03, 0.97, 0.0, 0.03, 0.97, 0.0, 0.0, 0.03, 0.97, 0.03, 0.97, 0.03, 1.0, 0.97, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.93, 1.0, 0.52, 1.0, 0.97, 1.0, 0.36, 1.0, 0.0, 0.97, 0.03, 0.0, 0.97, 0.0, 0.03, 0.0, 1.0, 0.0, 1.0, 0.03, 0.97, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.93, 1.0, 0.52, 0.97, 1.0, 0.97, 0.39, 0.97, 0.0, 1.0, 0.0, 0.0, 0.97, 0.03, 0.0, 0.03, 0.97, 0.03, 1.0, 0.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.93, 1.0, 0.49, 1.0, 0.97, 1.0, 0.36, 0.97, 0.03, 0.97, 0.0, 0.0, 1.0, 0.0, 0.03, 0.0, 1.0, 0.03, 0.97, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.93, 0.97, 0.52, 0.97, 1.0, 0.97, 0.36, 1.0, 0.0, 0.97, 0.0, 0.03, 0.97, 0.03, 0.0, 0.03, 1.0, 0.0, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.49, 1.0, 0.97, 0.97, 0.39, 0.97, 0.0, 0.97, 0.03, 0.0, 1.0, 0.0, 0.03, 0.03, 0.97, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 1.0, 0.97, 0.93, 0.97, 0.52, 0.97, 0.97, 1.0, 0.36, 0.97, 0.0, 1.0, 0.0, 0.03, 0.97, 0.03, 0.03, 0.0, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 1.0, 0.97, 1.0, 0.9, 1.0, 0.49, 0.97, 1.0, 0.97, 0.36, 0.97, 0.03, 0.97, 0.03, 0.0, 1.0, 0.03, 0.0, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.97, 1.0, 0.97, 0.93, 0.97, 0.49, 1.0, 0.97, 0.97, 0.36, 1.0, 0.0, 1.0, 0.0, 0.03, 1.0, 0.0, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.97, 1.0, 0.97, 1.0, 0.9, 0.97, 0.52, 0.97, 0.97, 0.97, 0.39, 0.97, 0.03, 0.97, 0.03, 0.03, 0.97, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.96, 1.0, 0.97, 1.0, 0.97, 0.9, 1.0, 0.49, 0.97, 0.97, 1.0, 0.36, 1.0, 0.0, 1.0, 0.03, 0.0, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97, 0.99, 0.97, 1.0, 0.97, 0.97, 0.93, 0.97, 0.49, 0.97, 1.0, 0.97, 0.39, 0.97, 0.03, 1.0, 0.0, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97, 1.0, 0.96, 1.0, 0.97, 0.97, 1.0, 0.9, 0.97, 0.49, 1.0, 0.97, 1.0, 0.36, 1.0, 0.03, 0.97, 0.03, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 1.0, 0.97, 1.0, 0.97, 0.99, 0.97, 0.97, 1.0, 0.97, 0.9, 0.97, 0.52, 0.97, 1.0, 0.97, 0.39, 1.0, 0.0, 1.0, 0.03, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 1.0, 0.97, 1.0, 0.97, 1.0, 0.96, 0.97, 1.0, 0.97, 0.97, 0.9, 1.0, 0.49, 1.0, 0.97, 1.0, 0.39, 0.97, 0.03, 1.0, 0.03, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 1.0, 0.97, 1.0, 0.97, 1.0, 0.97, 0.96, 1.0, 0.97, 0.97, 0.97, 0.93, 0.97, 0.52, 0.97, 1.0, 1.0, 0.36, 1.0, 0.03, 1.0, 0.03, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 1.0, 0.97, 1.0, 0.97, 1.0, 0.97, 0.97, 0.99, 0.97, 0.97, 0.97, 1.0, 0.9, 1.0, 0.49, 1.0, 1.0, 0.97, 0.39, 1.0, 0.03, 1.0, 0.03, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 1.0, 0.97, 1.0, 0.97, 1.0, 0.97, 0.97, 1.0, 0.96, 0.97, 0.97, 1.0, 0.97, 0.93, 0.97, 0.52, 1.0, 0.97, 1.0, 0.39, 1.0, 0.03, 1.0, 0.03, 0.03, 1.0, 0.03, 0.03, 0.03, 1.0, 0.03, 1.0, 0.03, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 0.03, 1.0, 1.0, 1.0, 1.0, 0.97, 0.97, 0.56, 1.0, 1.0, 1.0, 0.68, 0.97, 1.0, 0.97, 1.0, 0.97, 0.97, 1.0, 0.97, 0.96, 0.97, 1.0, 0.97, 1.0, 0.9, 1.0, 0.52, 0.97, 1.0, 1.0, 0.39]\n",
      "Best fitness : 0.82 at gen 90 with criterion : 0.7308137979869127 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.7975000000000025 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78, 1.0, 1.0, 1.0, 0.61, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 1.0, 0.87, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78, 1.0, 1.0, 0.73, 0.79, 0.6, 0.4, 0.51, 0.09, 0.4, 0.51, 0.0, 0.09, 0.4, 0.6, 0.4, 0.6, 0.49, 0.91, 0.6, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 0.87, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.78, 1.0, 0.64, 1.0, 0.39, 0.91, 0.09, 0.51, 0.4, 0.0, 0.6, 0.0, 0.49, 0.0, 1.0, 0.09, 0.91, 0.49, 0.6, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 0.87, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.69, 0.73, 0.91, 0.51, 0.88, 0.51, 0.0, 0.91, 0.09, 0.0, 0.6, 0.4, 0.09, 0.49, 0.51, 0.49, 1.0, 0.09, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.82, 1.0, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.42, 0.91, 0.6, 0.91, 0.39, 0.51, 0.49, 0.51, 0.09, 0.0, 1.0, 0.09, 0.4, 0.09, 1.0, 0.49, 0.6, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.85, 0.95, 1.0, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.91, 0.64, 0.78, 0.51, 0.91, 0.51, 0.48, 0.91, 0.09, 0.51, 0.09, 0.49, 0.51, 0.49, 0.09, 0.49, 1.0, 0.09, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 0.87, 0.98, 0.95, 1.0, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.91, 0.91, 0.73, 0.91, 0.29, 0.91, 0.6, 0.51, 0.88, 0.51, 0.09, 0.6, 0.4, 0.09, 1.0, 0.09, 0.49, 0.49, 0.6, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.87, 1.0, 0.98, 0.95, 1.0, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.91, 0.91, 1.0, 0.64, 0.91, 0.51, 0.78, 0.51, 0.6, 0.91, 0.48, 0.6, 0.0, 1.0, 0.09, 0.49, 0.6, 0.49, 0.49, 0.09, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 0.87, 1.0, 1.0, 0.98, 0.95, 1.0, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91, 1.0, 0.91, 0.91, 1.0, 0.91, 0.64, 0.91, 0.6, 0.91, 0.38, 0.51, 1.0, 0.6, 0.39, 0.6, 0.49, 0.6, 0.49, 0.09, 1.0, 0.49, 0.09, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 1.0, 0.87, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 1.0, 1.0, 0.94, 1.0, 1.0, 1.0, 0.91, 1.0, 0.91, 0.91, 1.0, 0.91, 0.91, 0.64, 1.0, 0.51, 1.0, 0.51, 0.38, 1.0, 0.51, 0.6, 0.48, 1.0, 0.09, 1.0, 0.09, 0.49, 1.0, 0.09, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.49, 0.87, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 1.0, 1.0, 0.94, 1.0, 0.91, 1.0, 0.91, 0.91, 1.0, 0.91, 0.91, 0.91, 0.73, 0.91, 0.6, 0.91, 0.6, 0.6, 0.69, 0.6, 0.6, 0.6, 0.88, 0.6, 0.49, 0.6, 0.49, 0.49, 0.6, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 0.36, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 1.0, 1.0, 0.85, 1.0, 0.91, 0.91, 1.0, 0.91, 0.91, 0.91, 1.0, 0.64, 1.0, 0.51, 1.0, 0.6, 0.51, 1.0, 0.38, 0.6, 0.6, 1.0, 0.48, 1.0, 0.09, 1.0, 0.49, 0.09, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 1.0, 0.87, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.95, 1.0, 0.91, 1.0, 0.85, 0.91, 1.0, 0.91, 0.91, 0.91, 1.0, 0.91, 0.73, 0.91, 0.6, 1.0, 0.51, 0.6, 1.0, 0.6, 0.38, 0.6, 1.0, 0.6, 0.88, 0.6, 0.49, 1.0, 0.09, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 1.0, 0.87, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 0.86, 1.0, 0.91, 0.91, 0.94, 0.91, 0.91, 0.91, 1.0, 0.91, 1.0, 0.64, 1.0, 0.6, 0.91, 0.6, 0.6, 1.0, 0.6, 0.6, 0.38, 1.0, 0.6, 1.0, 0.48, 1.0, 0.49, 0.6, 0.49, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.49, 0.87, 1.0, 1.0, 0.49, 1.0, 1.0, 1.0, 1.0, 0.91, 0.98, 0.86, 0.91, 1.0, 0.91, 0.85, 0.91, 1.0, 0.91, 1.0, 0.91, 0.73, 1.0, 0.51, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 0.78, 0.6, 1.0, 0.6, 0.88, 1.0, 0.09, 1.0, 0.49, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 1.0, 0.36, 1.0, 1.0, 1.0, 0.49, 1.0, 1.0, 0.91, 1.0, 0.91, 0.89, 0.95, 0.91, 0.91, 0.91, 0.94, 0.91, 1.0, 0.91, 1.0, 0.73, 0.91, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.38, 1.0, 0.6, 1.0, 0.88, 0.6, 0.49, 1.0, 0.49, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 1.0, 0.87, 0.49, 1.0, 1.0, 1.0, 0.49, 0.91, 1.0, 0.91, 0.91, 1.0, 0.89, 0.86, 0.91, 1.0, 0.91, 0.94, 0.91, 1.0, 1.0, 0.64, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 0.78, 0.6, 1.0, 1.0, 0.48, 1.0, 0.49, 1.0, 0.49, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.49, 0.87, 1.0, 0.49, 1.0, 1.0, 0.91, 0.49, 0.91, 0.91, 1.0, 0.91, 0.91, 0.89, 0.95, 0.91, 1.0, 0.91, 0.94, 1.0, 0.91, 0.73, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.38, 1.0, 1.0, 0.6, 0.88, 1.0, 0.49, 1.0, 0.49, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 1.0, 0.36, 1.0, 1.0, 0.49, 0.91, 1.0, 0.91, 0.4, 1.0, 0.91, 0.91, 0.91, 1.0, 0.89, 0.95, 0.91, 1.0, 1.0, 0.85, 1.0, 0.73, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 0.78, 1.0, 0.6, 1.0, 0.88, 1.0, 0.49, 1.0, 0.49, 0.49, 1.0, 0.49, 0.49, 0.49, 1.0, 0.49, 0.87, 0.49, 1.0, 0.91, 0.49, 0.91, 0.91, 1.0, 0.4, 0.91, 0.91, 1.0, 0.91, 1.0, 0.89, 0.95, 1.0, 0.91, 1.0, 0.94, 0.73, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 0.78, 0.6, 1.0, 1.0, 0.88]\n",
      "Best fitness : 0.86 at gen 100 with criterion : 0.7235056600070435 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.8236000000000014 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.2, 1.0, 0.03, 0.01, 1.0, 0.0, 0.0, 0.19, 1.0, 0.01, 1.0, 0.01, 1.0, 1.0, 0.13, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.6, 0.6, 0.43, 0.01, 0.6, 0.4, 0.0, 0.19, 0.6, 0.41, 0.6, 0.41, 0.6, 1.0, 0.53, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.59, 1.0, 0.03, 0.41, 0.6, 0.0, 0.4, 0.19, 0.6, 0.01, 1.0, 0.01, 1.0, 0.6, 0.53, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.99, 0.43, 0.01, 1.0, 0.0, 0.0, 0.59, 0.6, 0.01, 0.6, 0.41, 0.6, 1.0, 0.13, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.42, 0.41, 0.6, 0.4, 0.0, 0.19, 1.0, 0.01, 0.6, 0.01, 1.0, 0.6, 0.53, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.4, 1.0, 0.0, 0.4, 0.19, 0.6, 0.41, 0.6, 0.01, 0.6, 1.0, 0.13, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 0.99, 0.4, 0.0, 0.59, 0.6, 0.01, 1.0, 0.01, 0.6, 0.6, 0.53, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.39, 0.4, 0.19, 1.0, 0.01, 0.6, 0.41, 0.6, 0.6, 0.13, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.39, 0.59, 0.6, 0.41, 0.6, 0.01, 1.0, 0.6, 0.13, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.58, 1.0, 0.01, 1.0, 0.01, 0.6, 1.0, 0.13, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 0.99, 0.41, 0.6, 0.41, 0.6, 0.6, 0.53, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.4, 1.0, 0.01, 1.0, 0.6, 0.13, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 0.99, 0.41, 0.6, 1.0, 0.13, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.4, 1.0, 0.6, 0.53, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.41, 0.99, 1.0, 0.13, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.41, 1.0, 0.99, 0.53, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.41, 1.0, 1.0, 0.52, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.41, 1.0, 1.0, 0.53, 0.99, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.41, 1.0, 1.0, 0.53, 1.0, 0.99, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.61, 1.0, 1.0, 0.6, 1.0, 0.43, 0.41, 1.0, 0.4, 0.4, 0.59, 1.0, 0.41, 1.0, 0.41, 1.0, 1.0, 0.53, 1.0, 1.0, 0.99, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0]\n",
      "Best fitness : 0.92 at gen 110 with criterion : 0.7162706034069731 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.8661999999999976 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.54, 1.0, 0.47, 0.17, 1.0, 0.18, 0.17, 0.31, 1.0, 0.24, 1.0, 0.16, 1.0, 1.0, 0.27, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 0.74, 0.8, 0.67, 0.17, 0.8, 0.38, 0.17, 0.31, 0.8, 0.44, 0.8, 0.36, 0.8, 1.0, 0.47, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.73, 1.0, 0.47, 0.37, 0.8, 0.18, 0.37, 0.31, 0.8, 0.24, 1.0, 0.16, 1.0, 0.8, 0.47, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 0.99, 0.67, 0.17, 1.0, 0.18, 0.17, 0.51, 0.8, 0.24, 0.8, 0.36, 0.8, 1.0, 0.27, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.66, 0.37, 0.8, 0.38, 0.17, 0.31, 1.0, 0.24, 0.8, 0.16, 1.0, 0.8, 0.47, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.36, 1.0, 0.18, 0.37, 0.31, 0.8, 0.44, 0.8, 0.16, 0.8, 1.0, 0.27, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 0.99, 0.38, 0.17, 0.51, 0.8, 0.24, 1.0, 0.16, 0.8, 0.8, 0.47, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.37, 0.37, 0.31, 1.0, 0.24, 0.8, 0.36, 0.8, 0.8, 0.27, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.36, 0.51, 0.8, 0.44, 0.8, 0.16, 1.0, 0.8, 0.27, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.5, 1.0, 0.24, 1.0, 0.16, 0.8, 1.0, 0.27, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 0.99, 0.44, 0.8, 0.36, 0.8, 0.8, 0.47, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.43, 1.0, 0.16, 1.0, 0.8, 0.27, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 0.99, 0.36, 0.8, 1.0, 0.27, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.35, 1.0, 0.8, 0.47, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.36, 0.99, 1.0, 0.27, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.36, 1.0, 0.99, 0.47, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.36, 1.0, 1.0, 0.46, 1.0, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.36, 1.0, 1.0, 0.47, 0.99, 1.0, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.36, 1.0, 1.0, 0.47, 1.0, 0.99, 1.0, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.81, 1.0, 1.0, 0.74, 1.0, 0.67, 0.37, 1.0, 0.38, 0.37, 0.51, 1.0, 0.44, 1.0, 0.36, 1.0, 1.0, 0.47, 1.0, 1.0, 0.99, 1.0, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0]\n",
      "Best fitness : 0.94 at gen 120 with criterion : 0.7091078973729034 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.9269999999999993 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.84, 0.17, 1.0, 0.39, 0.79, 0.54, 1.0, 0.24, 1.0, 0.59, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Best fitness : 0.96 at gen 130 with criterion : 0.7020168183991743 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.9510000000000007 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.99, 1.0, 0.33, 1.0, 0.53, 0.97, 0.61, 1.0, 0.14, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Best fitness : 0.98 at gen 140 with criterion : 0.6949966502151825 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.9608000000000008 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.44, 1.0, 0.54, 1.0, 0.89, 1.0, 0.19, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Best fitness : 1.0 at gen 150 with criterion : 0.6880466837130307 , mutation : 0.005694549915852335 , static_epochs : 0\n",
      "Average sum : 0.9764000000000007 , rule weight : [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.98, 1.0, 0.74, 1.0, 0.69, 1.0, 0.99, 1.0, 0.42, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[[AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True]], [AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True]], [AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, 0, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, False, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True]], [AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, 0, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True]], [AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,1.0) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.96) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 0, True, 1, 1, 1, True, 1, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, 1, 1, 1, True, 0, True, 1, True, True, 1, True, True], AgentGA(322712066,0.98) with pattern [True, True, True, 1, 1, 1, 1, True, True, 1, 1, 1, 1, True, True, True, True, True, 1, 1, True, True, True, True, 1, 1, 1, 1, True, True, 1, True, 1, True, 1, 1, True, False, 1, 1, True, 1, True, 1, True, True, 1, True, True]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15100"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness = lab3_lib.make_problem(10)\n",
    "trainer = AgentIslandsTraining(100,fitness,k=1000,island_number=5,agent_type=Agent.AgentType.PATTERN)\n",
    "best_agent = trainer.train(5000)\n",
    "fitness.calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A dumb approach to the problem\n",
    "Trying to optimize the problem by trying to maximize the fitness bit-by-bit, converge almost instantly for n = 1, but can't find anything with 2,5,10 problem size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def dummy_solution(fitness):\n",
    "    k = 1000\n",
    "    agent_slighly_smarter = [random.uniform(0,1) < 0.5 for _ in range(k)]\n",
    "    agent_fitness = fitness(agent_slighly_smarter)\n",
    "    while agent_fitness < 1.0:\n",
    "        for i in range(k):\n",
    "            temp = deepcopy(agent_slighly_smarter)\n",
    "            temp[i] = not temp[i]\n",
    "            temp_fitness = fitness(temp)\n",
    "            if temp_fitness > agent_fitness:\n",
    "                agent_slighly_smarter = temp\n",
    "                agent_fitness = temp_fitness\n",
    "        print(agent_fitness)\n",
    "    #print(fitness(agent_slighly_smarter))\n",
    "    #print(fitness.calls)\n",
    "    return agent_slighly_smarter\n",
    "fitness = lab3_lib.make_problem(1)\n",
    "print(fitness(dummy_solution(fitness)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing(k : int,fitness : AbstractProblem,lam):\n",
    "    agent = AgentGA([random.uniform(0,1) < 0.5 for _ in range(k)],fitness)\n",
    "    gen = 0\n",
    "    gene_modifier = 2\n",
    "    mutation_rate = gene_modifier / k\n",
    "    while agent.fitness < 1.0:\n",
    "        offspring = []\n",
    "        for _ in range(lam):\n",
    "            agent_temp = deepcopy(agent)\n",
    "            agent_temp.mutation(mutation_rate)\n",
    "            agent_temp.compute_fitness(fitness)\n",
    "            offspring.append(agent_temp)\n",
    "        offspring.append(agent)\n",
    "        offspring.sort(key=lambda x : x.fitness , reverse=True)\n",
    "        agent = offspring[0]\n",
    "        gen += 1\n",
    "        if gen % 10 == 0:\n",
    "            print(f\"gen {gen} : Best fitness : {agent.fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AgentGA.__init__() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aless\\Documents\\Codice\\compIntelligence\\labs\\lab3\\lab3.ipynb Cella 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fitness \u001b[39m=\u001b[39m lab3_lib\u001b[39m.\u001b[39mmake_problem(\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m hill_climbing(\u001b[39m1000\u001b[39;49m,fitness,\u001b[39m40\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fitness\u001b[39m.\u001b[39mcalls\n",
      "\u001b[1;32mc:\\Users\\aless\\Documents\\Codice\\compIntelligence\\labs\\lab3\\lab3.ipynb Cella 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhill_climbing\u001b[39m(k : \u001b[39mint\u001b[39m,fitness : AbstractProblem,lam):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     agent \u001b[39m=\u001b[39m AgentGA([random\u001b[39m.\u001b[39;49muniform(\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m) \u001b[39m<\u001b[39;49m \u001b[39m0.5\u001b[39;49m \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(k)],fitness)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     gen \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/Documents/Codice/compIntelligence/labs/lab3/lab3.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     gene_modifier \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: AgentGA.__init__() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "fitness = lab3_lib.make_problem(2)\n",
    "hill_climbing(1000,fitness,40)\n",
    "fitness.calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

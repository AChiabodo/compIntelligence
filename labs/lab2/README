**Author**: Alessandro Chiabodo
 - Student ID: `s309234`
 - Institutional Email: `s309234@studenti.polito.it`
 - Repository : [AChiabodo/compIntelligence](https://github.com/AChiabodo/compIntelligence.git)
 
Resources Used:
 - [squillero/computational-intelligence](https://github.com/squillero/computational-intelligence) : Main source of material for the lab requirements and code
 - Stuart Russel, Peter Norvig, *Artificial Intelligence: A Modern Approach* [4th edition] : Partial source for ES algorithms
 - [Wikipedia](https://en.wikipedia.org/wiki/Nim) : Main source for the game rules


# Lab2 - ES Algorithm for Nim
Nim is a mathematical strategy game in which two players take turns removing (or "nimming") objects from different piles or stacks. In this version of the game (called 'mis√®re') in each turn, a player can remove one or more objects from a single row, and the player who removes the last object loses.

## Task 0: Definition of Classes and Utils functions
In addition to the NimSum function already provided and used both for the expert agent and in the 'benchmarking' phase of the algorithm, several new classes and functions were defined and subsequently used in both assigned tasks.
 - *Player class* : main interface for interoperability between different players classes, contains the definition of the main methods called "play", used to define the move of the player
 - *Multiple Matches* : util function that calculate the outcomes of N different games where each time one player starts at random from among the two

## Task 1: Find a rule-based Nim Player
To develope an "expert" agent able to win almost all games we'll need to find some basic rules that'll allow our algorithm to choose the best move out of all possible
 - A first attempt can be seen in `EasyRuleBasedPlayer` that analizes only the number of non-void columns and act accordingly
 - Another example can be seen in the `OptimalPlayer` based on the analisys of the NimSum of each move (the code is based on the original implementation from [squillero/computational-intelligence](https://github.com/squillero/computational-intelligence) )
Neither has a high win rate when used against another player who is slightly more intelligent than a "random" player. Now we've two alternatives, to optimize the Rule-based agent or to follow a *simulative* approach. Here my results are :
 - `AdvancedRuleBasedPlayer` : An optimized version of the original `OptimalPlayer` that also uses the number of "big" and "non-empty" rows to make its decisions, allowing him to have an 80% win rate against the previous expert agent
 - `SimulativePlayer` : Following a more computational-heavy path, here we're computing all possible outcomes given by each move and then choosing the one that allows an higher win probability
The last two models are almost equal in terms of win rate, with `SimulativePlayer` slightly better, but with higher computational cost and lower scalability.
Now that we've defined some agents that are able to win almost certainly a game is time to create a more "intelligent" player that can learn from its mistakes

## Task 2: Define an Evolution Strategy
Evolution strategies and, more generally, evolutionary algorithms allow us to "train" an intelligent player. 
To achieve that we need a way to define some "rules" that our new agent will try to learn and optimize, and a possible (but computationally intense) way of doing so is to define a rule for each possible state that we could encounter in the game. 
In other words, we calculate *all possible combinations* of rows in the game, and for each individual in our player population, we assign *one (random) move* to each of them.
To obtain an individual (or player) able to compete with the expert agents defined before we'll need to train them, evaluate them and choose only the best at each generation.

